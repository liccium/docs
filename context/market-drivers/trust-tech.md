# Trust tech

The abundance and widespread dissemination of media content online poses significant challenges for users in terms of analysing and verifying the data integrity, claims and attribution to the content.

This lack of transparency creates an environment that fosters the spread of fake news and disinformation campaigns. Manipulation and misappropriation of digital media content has damaging social and economic effects for democratic societies, going as far as threatening to influence elections, perpetuating discrimination, and xenophobia, and engaging in cyber warfare.

Since 2017, many institutions and initiatives have committed themselves to the goal of combating fake news and disinformation. They provide scientific research, social education to improve media literacy, and tools for fact-checking to help users identify fake news. These efforts focus on analysing media content, metadata, and identifiable sources. They rely on the use of media forensic methods, analysing dissemination patterns, and assessing the trustworthiness of accounts and identities supported by AI models and other methods.

{% hint style="info" %}
Recent examples: Euvsdisinfo; EDMO European Digital Media Observatory; Bellingcat; Truly Media; START2THINK Collection of Fact-checking Tools; Digital Forensics; Research Lab; The Atlantic Council; DisinfoPortal; Alliance for Securing Democracy; NATO StratCom Centre of Excellence; Hybrid CoE; Polygraph; Graphika; Computational Propaganda Project, OII; Arena, LSE; Institute for Strategic Dialogue; New Knowledge; StopFake; Ukraine Crisis Media Center; Free Russia Foundation; European Values Think-Tank; GLOBSEC.
{% endhint %}
